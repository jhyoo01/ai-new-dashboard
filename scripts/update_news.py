#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AI News Updater for GitHub Pages
ë§¤ì¼ ìµœì‹  AI ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•˜ê³  index.htmlì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
"""

import os
import re
import json
import time
import requests
from datetime import datetime
from bs4 import BeautifulSoup
from collections import defaultdict


class AINewsUpdater:
    """AI ë‰´ìŠ¤ ìë™ ì—…ë°ì´íŠ¸"""
    
    def __init__(self):
        self.news_data = []
        self.categories = {
            'llm': ['ChatGPT', 'GPT', 'Claude', 'Gemini', 'LLM', 'OpenAI', 'Anthropic', 'ëŒ€í˜•ì–¸ì–´ëª¨ë¸'],
            'industry': ['AI íˆ¬ì', 'AI ìŠ¤íƒ€íŠ¸ì—…', 'ì‚¼ì„±', 'LG', 'NVIDIA', 'êµ¬ê¸€', 'AI ê¸°ì—…'],
            'research': ['AI ì—°êµ¬', 'DeepSeek', 'ë…¼ë¬¸', 'ì•Œê³ ë¦¬ì¦˜', 'MIT', 'Stanford'],
            'ml_dl': ['ë¨¸ì‹ ëŸ¬ë‹', 'ë”¥ëŸ¬ë‹', 'ì‹ ê²½ë§', 'Machine Learning', 'Deep Learning'],
            'application': ['AI í™œìš©', 'AI ì„œë¹„ìŠ¤', 'ì‹ ì•½', 'ì˜ë£Œ', 'ììœ¨ì£¼í–‰']
        }
    
    def search_ai_news(self):
        """AI ë‰´ìŠ¤ ê²€ìƒ‰ (Google News ìŠ¤íƒ€ì¼)"""
        print("ğŸ” AI ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
        
        keywords = [
            'AI ë‰´ìŠ¤', 'ChatGPT', 'Claude', 'OpenAI', 'Anthropic', 
            'Google AI', 'DeepSeek', 'ì¸ê³µì§€ëŠ¥', 'LLM', 'Gemini',
            'AI ì—°êµ¬', 'AI íˆ¬ì', 'AI ê·œì œ'
        ]
        
        for keyword in keywords[:5]:  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ
            try:
                news = self.fetch_news_for_keyword(keyword)
                self.news_data.extend(news)
                time.sleep(2)  # Rate limiting
            except Exception as e:
                print(f"âš ï¸  {keyword} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # ì¤‘ë³µ ì œê±°
        seen = set()
        unique_news = []
        for item in self.news_data:
            title_hash = hash(item['title'])
            if title_hash not in seen:
                seen.add(title_hash)
                unique_news.append(item)
        
        self.news_data = unique_news[:12]  # ìµœëŒ€ 12ê°œ
        print(f"âœ… {len(self.news_data)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        
        return self.news_data
    
    def fetch_news_for_keyword(self, keyword):
        """í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰"""
        news_items = []
        
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” News API ë“±ì„ ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ìƒ˜í”Œ ìƒì„±
        base_sources = ['TechCrunch', 'ì¡°ì„ ì¼ë³´', 'The Verge', 'MIT Technology Review', 
                       'Forbes', 'Bloomberg', 'Reuters', 'Nature', 'Ars Technica', 'ì¤‘ì•™ì¼ë³´']
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ê°€ìƒ ë‰´ìŠ¤ ìƒì„± (ì‹¤ì œë¡œëŠ” APIë‚˜ í¬ë¡¤ë§ í•„ìš”)
        category = self.classify_category(keyword)
        
        news_items.append({
            'title': f'{keyword} ê´€ë ¨ ìµœì‹  AI ê¸°ìˆ  ë™í–¥',
            'source': base_sources[len(news_items) % len(base_sources)],
            'category': category,
            'date': datetime.now().strftime('%Y-%m-%d'),
            'time': self.get_random_time(),
            'importance': round(7.5 + (len(keyword) % 3) * 0.5, 1),
            'description': f'{keyword}ì— ëŒ€í•œ ìµœì‹  AI ì—…ê³„ ë™í–¥ê³¼ ê¸°ìˆ  ë°œì „ ì†Œì‹ì…ë‹ˆë‹¤. ê¸€ë¡œë²Œ AI ê¸°ì—…ë“¤ì˜ í˜ì‹ ì ì¸ ì›€ì§ì„ì´ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.',
            'link': f'https://www.google.com/search?q={keyword}+AI+news',
            'keywords': [keyword, 'AI', 'ê¸°ìˆ ']
        })
        
        return news_items
    
    def classify_category(self, keyword):
        """í‚¤ì›Œë“œë¡œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        keyword_lower = keyword.lower()
        
        for category, keywords in self.categories.items():
            if any(k.lower() in keyword_lower for k in keywords):
                return category
        
        return 'llm'  # ê¸°ë³¸ê°’
    
    def get_random_time(self):
        """ëœë¤ ì‹œê°„ ìƒì„±"""
        import random
        hours = random.randint(1, 14)
        if hours == 1:
            return '1ì‹œê°„ ì „'
        elif hours < 24:
            return f'{hours}ì‹œê°„ ì „'
        else:
            return '1ì¼ ì „'
    
    def generate_html(self):
        """ì—…ë°ì´íŠ¸ëœ HTML ìƒì„±"""
        print("ğŸ“ HTML ìƒì„± ì¤‘...")
        
        if not self.news_data:
            print("âš ï¸  ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.news_data = self.get_default_news()
        
        # JavaScript ë°ì´í„° ë¶€ë¶„ ìƒì„±
        news_json = json.dumps(self.news_data, ensure_ascii=False, indent=12)
        
        # ê¸°ì¡´ HTML í…œí”Œë¦¿ ì½ê¸°
        with open('index.html', 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        # NEWS_DATA ë¶€ë¶„ êµì²´
        pattern = r'const NEWS_DATA = \[.*?\];'
        replacement = f'const NEWS_DATA = {news_json};'
        
        updated_html = re.sub(pattern, replacement, html_content, flags=re.DOTALL)
        
        # ë‚ ì§œ ì—…ë°ì´íŠ¸
        current_date = datetime.now().strftime('%Y-%m-%d')
        updated_html = re.sub(
            r"date: '\d{4}-\d{2}-\d{2}'",
            f"date: '{current_date}'",
            updated_html
        )
        
        return updated_html
    
    def get_default_news(self):
        """ê¸°ë³¸ ë‰´ìŠ¤ ë°ì´í„° (ì‹¤íŒ¨ ì‹œ í´ë°±)"""
        return [
            {
                'id': 1,
                'title': 'OpenAI, ìµœì‹  AI ëª¨ë¸ ë°œí‘œ',
                'source': 'TechCrunch',
                'category': 'llm',
                'date': datetime.now().strftime('%Y-%m-%d'),
                'time': '2ì‹œê°„ ì „',
                'importance': 9.5,
                'description': 'OpenAIê°€ ìµœì‹  AI ëª¨ë¸ì„ ê³µê°œí•˜ë©° ì—…ê³„ì— ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤.',
                'link': 'https://www.google.com/search?q=OpenAI+latest+news',
                'keywords': ['OpenAI', 'AI', 'LLM']
            },
            {
                'id': 2,
                'title': 'Google Gemini ì—…ë°ì´íŠ¸ ë°œí‘œ',
                'source': 'The Verge',
                'category': 'llm',
                'date': datetime.now().strftime('%Y-%m-%d'),
                'time': '4ì‹œê°„ ì „',
                'importance': 8.8,
                'description': 'Googleì´ Geminiì˜ ëŒ€ê·œëª¨ ì—…ë°ì´íŠ¸ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.',
                'link': 'https://www.google.com/search?q=Google+Gemini+news',
                'keywords': ['Google', 'Gemini', 'AI']
            }
        ]
    
    def save_html(self, html_content):
        """HTML íŒŒì¼ ì €ì¥"""
        with open('index.html', 'w', encoding='utf-8') as f:
            f.write(html_content)
        print("âœ… index.html ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
    
    def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("ğŸš€ AI News Updater ì‹œì‘...")
        print("=" * 60)
        
        try:
            # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
            self.search_ai_news()
            
            # 2. HTML ìƒì„±
            html_content = self.generate_html()
            
            # 3. ì €ì¥
            self.save_html(html_content)
            
            print("=" * 60)
            print("âœ¨ ì—…ë°ì´íŠ¸ ì™„ë£Œ!")
            print(f"ğŸ“… ì—…ë°ì´íŠ¸ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print(f"ğŸ“Š ì´ {len(self.news_data)}ê°œ ê¸°ì‚¬")
            
            return 0
        
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return 1


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    updater = AINewsUpdater()
    return updater.run()


if __name__ == "__main__":
    exit(main())
